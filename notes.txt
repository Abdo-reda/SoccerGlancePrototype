TODO:
    * Rename generate_transcrptions
    * Move the folder models inside the build_models
    * Make the folder Tests include logs
    * Should push processes to a list and then loop over that list and terminate them.
    * Also, I should look into why I coudn't generate highlights and actions at the same time 
    

------------ API stuff 

### integrating with the API

- The Api is running on http://10.40.51.75:8000
- Scehdule, when time is satisfied, 
    //start streaming match
    //send match is live
    //either the model server is started or automatically detects there is a stream
- Model server started
    //generate chunks
    //generate transcriptions
    //generate highlights/summaries from chatGPT or elsewhere
    //send the highlight
- Match ends
    //detect that
    //send match is finished.

--> how will the user/client gets access to the highlights?


---- Others

* create folder run_[data/time]
    //this folder will contain a log file and an outputfile


-------- RTMP server Notes 
[https://www.digitalocean.com/community/tutorials/how-to-set-up-a-video-streaming-server-using-nginx-rtmp-on-ubuntu-20-04] 
[https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-20-04]
[https://serverspace.io/support/help/osnovnye-komandy-ufw]

I have decided to use nginx rtmp module, hopefully this works out.
    - I installed (sudo apt install) [https://gist.github.com/amitkhare/55155f9ae97013c45eff84eef84ab244]
        - nginx
        - libnginx-mod-rtmp -y
       

Also here are some commands: 
    - systemctl status nginx //gets status of server I think
    - sudo systemctl restart nginx //restarts server 
    - sudo systemctl reload nginx.service
    - sudo ufw app list
    - sudo ufw status
    - sudo ufw allow 1935/tcp
    - sudo ufw allow 'Nginx HTTP' //or FULL
    - xdg-open /etc/nginx //this the folder that contains nginx.config file ..

Other Commands:
    - xdg-open . //opens the current folder in file explorer isa 
    - sudo -i nautilus //opens root gui file explorer
    - sudo /usr/local/nginx/sbin/nginx -s stop
    - sudo /usr/local/nginx/sbin/nginx
    - sudo netstat -tanpl|grep nginx

------------------ Testing:
ffmpeg -re -i /home/g05-f22/Downloads/MatchTest.mkv -c:v libx264 -preset veryfast -tune zerolatency -c:a aac -f flv rtmp://localhost:1935/live/mystream
ffmpeg -re -i /home/g05-f22/Downloads/MatchTest.mkv -c:v libx264 -preset veryfast -tune zerolatency -c:a aac -f flv 'rtmp://localhost:1935/live/mystream?fileName=MatchTest.mkv'


ffmpeg -i rtmp://localhost:1935/live/mystream -f segment -segment_time 30 -codec:a pcm_s16le -ar 44100 -ac 2 output_%03d.wav
ffmpeg -i rtmp://localhost:1935/live/mystream -f segment -segment_time 10 -codec:a libmp3lame -qscale:a 2 output_%03d.mp3
ffmpeg -i rtmp://localhost:1935/live/mystream -f segment -segment_time 30 -codec:a flac -ar 44100 -ac 2 output_%03d.flac 
ffmpeg -i rtmp://localhost:1935/live/mystream -f segment -segment_time 5 -codec:v libx264 -preset faster -crf 22 -pix_fmt yuv420p -an output_%03d.mkv
ffmpeg -i rtmp://localhost:1935/live/mystream -f segment -segment_time 5 -codec:v libx264 -preset faster -crf 22 -pix_fmt yuv420p -an -movflags +faststart output_%03d.mp4

//Ultra mode
ffmpeg -i rtmp://localhost:1935/live/mystream -f tee "[select=a:f=matroska:map=a,split=2][select=a:f=wav:map=0,split=2]" -map 0:v -segment_time 5 -codec:v libx264 -preset ultrafast -crf 22 -pix_fmt yuv420p -map 0:a -segment_time 30 -codec:a pcm_s16le -ar 44100 -ac 2 -f segment "output_mkv_%03d.mkv" -f segment "output_wav_%03d.wav"
ffmpeg -i rtmp://localhost:1935/live/mystream -f tee "[select=a:f=mkv]output.mkv|[select=a:f=wav]output.wav"


-c:a:137 libvorbis 
-c copy
-codec:a aac -b:a 128k
-codec:a libmp3lame -qscale:a 2 
-codec:a pcm_s16le -acodec copy

--presets: ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow

conda install -c conda-forge x264


------------ NVIDIA stuff

export LD_LIBRARY_PATH=/home/g05-f22/miniconda3/envs/MyPrototype/lib/libcudnn.so.8
export LD_LIBRARY_PATH=/home/g05-f22/miniconda3/envs/MyPrototype/lib:$LD_LIBRARY_PATH
LD_LIBRARY_PATH: /home/g05-f22/miniconda3/envs/MyNewPrototype/lib/python3.9/site-packages/cv2/../../lib64:/home/g05-f22/miniconda3/envs/MyPrototype/lib/libcudnn.so.8




/home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib

---------- Installing TENSOR_RT

Download TensorRT version: [https://developer.nvidia.com/nvidia-tensorrt-8x-download]
    - GA is stable version, EA stands for early access 
    - Three methods for Linux:
        . Debian
        . RPM 
        . TAR --> Recommended I think but you will have to manually change and update LD_LIBRARY_PATH 

LD_LIBRARY_PATH: Points to the TensorRT library directory.
PATH: Points to the TensorRT binary directory.
PYTHONPATH: Points to the TensorRT Python library directory.

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib //this concatonates the existing paths and adds an additional path .. 

python -m pip install "/home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/python/tensorrt-8.5.3.1-cp39-none-linux_x86_64.whl" --force-reinstall
python -m pip install /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/uff/uff-0.6.9-py2.py3-none-any.whl
python -m pip install /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/graphsurgeon/graphsurgeon-0.4.6-py2.py3-none-any.whl
python -m pip install /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/onnx_graphsurgeon/onnx_graphsurgeon-0.3.12-py2.py3-none-any.whl


ln -s /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib/libnvinfer.so.8 /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib/libnvinfer.so.7
ln -s /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib/libnvinfer_plugin.so.8 /home/g05-f22/Desktop/ActionSpotting/Others/TensorRT/TensorRT-8.5.3.1/lib/libnvinfer_plugin.so.7




--------------- Whisper 

* start and end time for each utterance.
for result in results:
    start_time = result["start_time"]
    end_time = result["end_time"]
    utterance = result["text"]

//an alternative approach .. https://github.com/linto-ai/whisper-timestamped or https://cloud.google.com/speech-to-text ?! maybe its bad actually, no capiche


-------------- NGINX RTMP 


ffmpeg -re -i /home/g05-f22/Downloads/MatchTest.mkv -c:v libx264 -preset veryfast -tune zerolatency -c:a aac -f flv rtmp://localhost:1935/live/mystream


---------------------

* Experiment with accuracy:
    - different ranges 
    - different matches
    - //"not_found" a lot <-- keep it in mind, metric in mind.
    - //merge both approaches <-- 

* Demo:
    - realtime 
    - offline 
      . //no client application ....  

* Slides:
    . 

* Summarization:





------------------- Old Notes 

- Made the import inside the directories relative by using . 
    //from .model import Model

- Upgraded Tensorflow version hopefully this works ... why the internet so slow ....  original ==2.3.0 
    https://www.tensorflow.org/install/pip

- The missing library (7) is optional I think and is realted to tenosRT which is not needed right now ... 
    //the actual 

- Tensor RT is probably not needed ...

- PCI_ID 0000:02:00.0 ... I think

- Whisper requires python version 3.9, I am scared that if I change the python version then the whole prototype will collapse, could create another conda env just in case ...
    - for new version git+https://github.com/openai/whisper.git
    - for python=3.7 version openai-whisper==20230124

- Something wrong when pip3 install -r requirements.txt, I am doing it one by one manually.
    - I found the problem, it was opencv-python==3.4.11.41 
    - I will install an updated opencv ... 


